![img](file:///C:\Users\asus\AppData\Local\Temp\ksohtml\wps30D6.tmp.jpg)

![img](file:///C:\Users\asus\AppData\Local\Temp\ksohtml\wps30D7.tmp.jpg) 

![img](file:///C:\Users\asus\AppData\Local\Temp\ksohtml\wps30D8.tmp.jpg) 

![img](file:///C:\Users\asus\AppData\Local\Temp\ksohtml\wps30D9.tmp.jpg) 

系统模块的来源是经验

库函数library 调用

文件系统 数据管理系统 独立的系统

 

程序和系统的交互：

1.框架framework：Spring Express  不同的前端设计语言都有其框架，很多应用通过一种模式构建，所以不同重复写，其实就是留空，空的东西决定逻辑

2.API（库）

 

例1.为什么是独立运行的系统，不是库的形式（相当于别人写好了一部分的程序，把它拉过来去运行）？

复杂的功能不一定要变成系统，数据管理系统是要用各种硬件去处理这些数据，调用cpu去维护，去调度处理，保证数据完整，是要自己取管理cpu，硬盘，要管理的话就不是library，是随时随地； 多个数据要共享，被若干个共享的话必须是系统，没法协调，不能是library ；如果只是嵌在应用中的一段程序，如果不设立屏障的话，容易被篡改，系统可以随时备份，保证本身的完好。

例2：什么叫好的模块化？

并不是为了提高程序运行效率，基本目的是为了提高开发的效率，是人在制作应用程序的效率，模块之间的交互尽量简单，以至于模块外部看不到细节。

开发是把一件复杂事情变成一步步，分工需要模块化，做完一个再做一个

在维护程序的过程中，有人要去改，做的好的模块化有利于别人去理解，可读性会增加。

例3：数据管理系统要变成好的模块应该满足的条件？

DBMS职责明确，一件事情要么全部给他做，要么就不做

不明确的结果：程序和系统就有很多复杂交互，不利于模块化，如数据存进去就行了，而不用担心会不会丢失

数据访问简单，接口问题不是那么容易的，对于文档数据库与SQL数据库

尽量所有数据的交给DBMS管理

运行在独立的机器上是为了提高整个系统的可靠性，如集群

 

Week2:

基本概念：

数据库是DBMS的最早原型，数据放进去，需要时去查找，更新修改，不丢失，一致性和准确性

功能：CRUD

Create 创建数据项

Read 读取数据

Update 修改

Delete 删除

增删改查

OOP  object oriented programming

数据看成对象 对象如何描述，如所有人放在一张表；每个人的信息打包在一起变成文档

描述对象的结构--数据模型 根据不同数据模型，便又不同系统，如关系、文档数据库系统

 

文档模型：

数据库，每一个库对应一个应用

Collection 文档集 

Document 文档 ![img](file:///C:\Users\asus\AppData\Local\Temp\ksohtml\wps30E9.tmp.jpg) 

文档里面还可以嵌套文档![img](file:///C:\Users\asus\AppData\Local\Temp\ksohtml\wps30EA.tmp.jpg)

其实就是一个树的结构：![img](file:///C:\Users\asus\AppData\Local\Temp\ksohtml\wps30EB.tmp.jpg)

每一个对象都是通过一个文档中的键值对来描述，同一类型的文档集合起来形成文档集，多个文档集被同一个应用去使用，即数据库。

 

MongoDB

![img](file:///C:\Users\asus\AppData\Local\Temp\ksohtml\wps30EC.tmp.jpg) 

![img](file:///C:\Users\asus\AppData\Local\Temp\ksohtml\wps30ED.tmp.jpg) 

![img](file:///C:\Users\asus\AppData\Local\Temp\ksohtml\wps30EE.tmp.jpg) 

文档的存储

HHD磁盘 SSD闪存 内存必须带电才不会丢失，硬盘不会

![img](file:///C:\Users\asus\AppData\Local\Temp\ksohtml\wps30EF.tmp.jpg) 

![img](file:///C:\Users\asus\AppData\Local\Temp\ksohtml\wps3100.tmp.jpg) 

![img](file:///C:\Users\asus\AppData\Local\Temp\ksohtml\wps3101.tmp.jpg) 

光页面堆积的结构对于创建友好，但是对于其他不友好，代价比较大，每次都要找到，扫描整个磁盘的空间，时间长。所以需要索引，可以看成函数，不用遍历

B树索引，点查询，给了一个文档的属性=/>/<值，对一个单一的属性就可以用该结构。

 

![img](file:///C:\Users\asus\AppData\Local\Temp\ksohtml\wps3102.tmp.jpg) 

任何一个结点的键值个数范围![img](file:///C:\Users\asus\AppData\Local\Temp\ksohtml\wps3103.tmp.jpg) 保证树的平衡，执行的效率

![img](file:///C:\Users\asus\AppData\Local\Temp\ksohtml\wps3104.tmp.jpg) 

![img](file:///C:\Users\asus\AppData\Local\Temp\ksohtml\wps3105.tmp.jpg) 

必须要用户自己指定要在哪一类文档创建哪一类索引，

并不需要为每一个属性都创建一个索引，索引是复杂的，所使用的存储空间可能和collection差不多；更新数据后需要更新索引。

\1. 常用属性

\2. 不常被修改，属性稳定，修改是先要删除再插入

\3. 索引的有效性 如性别，一半

多值属性上的索引，关系数据库会讲

![img](file:///C:\Users\asus\AppData\Local\Temp\ksohtml\wps3106.tmp.jpg) 

如果用ID作为索引，那么inode结构可以去掉，既可以用来访问，也可以用来串联。

 

第1题：一个文档数据库里面有两类对象，书（book）和人（person）。书和人之间存在一种写作的关系，即某个人是某本书的作者。请问这种写作关系的信息应该如何存放？

一个对象是另一个对象的父亲，用程序里就用引用 reference、指针（C）

引用属性必须要去唯一识别另外一个对象，名字没有办法去唯一识别一个对象，在文档数据库里有一个特殊的属性ID，虽然这个值没有任何的意义

第2题：查阅mongoDB手册

第3题：对于程序开发者来说，程序写起来复杂；不是原子的

![img](file:///C:\Users\asus\AppData\Local\Temp\ksohtml\wps3107.tmp.jpg) 

1.碎片化，直接存储文档，插入再删除会逐渐产生一个个过小而无法利用的空洞

处理方法：回收 把洞给扒出来，数据塞在一起，空洞塞在一起，代价高，可能80%的数据要移动

如果把空间分成页：

如果空间很小，就不需要整，也就是局部化，整个管理的代价就会降低

\2. 有利于提升数据访问的性能：连续去访问的性能比跳着去访问的性能要好很多？分页的有利于把要访问的数据放在同一页里

\3. 不一定，缓存是用来把经常被访问的数据放在里面，比普通的访问快，但小，热数据放在缓存中，可能当页比较大时，有可能有一部分是热数据，大部分是冷数据，那么冷数据侵蚀了空间，所以不能。。

\4. 有利于减少空间管理的成本，以页为单位，否则是要以数据为单位，大小不统一，会变得简单

![img](file:///C:\Users\asus\AppData\Local\Temp\ksohtml\wps3108.tmp.jpg) 

你预期接下来不会被再次使用

A. 但是还是要落实到硬盘，会断电，节省的代价会有限

经常去读的，但很少去改的，如Inode

防误操作，会有一个缓存区，而不是缓存（是稀缺的资源，加速访问）

 

思考题1：当我们对存储空间进行分页管理的时候，页的大小通常是一个设计要点。有的数据管理系统选择使用比较小的页，如2KB或4KB。而另一些系统会使用比较大的页，比如4MB或8MB。请问：小页面对什么情况有利？大页又对什么情况有利？我们确定页的大小时应该考虑哪些因素？

小页面：可以解决碎片的问题；大页面：有利于提升数据访问的性能

页面太大容易产生空间浪费，程序假如只使用了1个字节却被分配了10M的页面，这岂不是极大的浪费，页面太小会导致页表占用空间过大，所以页面需要折中选择合适的大小

 

思考题2：如课程中提到的，内存通常被数据管理系统作为缓存使用。缓存的数据单元可以有不同的选择；可以是页，即当访问完一页后，将整个页继续保留在内存中，以期后面再次访问该页就无需再从硬盘获取；也可以是文档，即当访问完一页中的某个文档后，将这个文档继续保留在内存中，而将页移除，以期后面再次访问该文档时无需再从硬盘获取。请问：页缓存和文档缓存各自的优势和劣势是什么？什么情况下，我们可以考虑使用文档缓存

页缓存所占的内存空间会较小

 

1ns=10-9s  CPU访问内存100ns 即内存墙 cache也分指令、数据的cache

10ms硬盘，大部分用闪存

105IOPS 读取 随机读与顺序读差异大

存储系统中最明显的差异就是缓存，就是在ram有没有命中，那什么时候容易在缓存命中？

数据访问的局部性（挨着一个一个去访问即空间局部性）好比较容易在缓存上命中，尽量在金字塔上面，不用了再扔掉。

 

一页包含多个文档

文档放在缓存了，要单独组织这个文档，每个文档都有ID，有利于减少缓存的空间，但管理成本高

如果是一个个挨着去访问，用页去做缓存是有效的

 

 

 

 

真正的应用系统都是面向对象的，把数据成一个个对象的信息

很多时候要找的对象就是一个，所以用findone就可以了

Update,delete先找到，即查询条件，然后在做

 

内存管理

文件系统

两者之间有相似的地方，文件系统有一个存储空间管理

内存也有空间管理，C语言的空间管理是显性的要malloc，free一个空间；使用面向对象的时候都对应一个个相应的空间  虚拟内存：对空间管理的设计

都分成一页一页，4KB，一般不会调

页表：对应于物理空间  一个指针就有8byte，页表就会很大，页表是用来管理的，当页越小的时候，管理成本越高；页太大，就会形成浪费

 

Oracle 以8KB分页，可能有很多随机的访问

MongoDB  64KB到1/4MB 都是可以调的

64KB 而不是8KB，

访问数据的性能变好

连续访问比跳着好，一个文档由很多页构成，这样页的个数变少

当页变大也会造成性能变差：

\1. 访问的数据本来就很少，本身访问的内容就变多了，读（写）放大

\2. 当页很大的时候要cache起来，不利于提高cache的利用率

当一次性要访问很多数据的时候，如播放电影，顺序连续访问，页大的时候是有利的，不用跳来跳去，但需要跳来跳去即随机访问，I/O和cache的资源

文件系统一页是64KB整体的性能是最好的，所以可能提高页的大小。。

 

文件系统中一页一页，Linux页大大小不一定Ext3 4KB，可以调

有的文件系统：

分布式文件系统HDFS 一个块（页）的大小block  128MB，很大，由应用场景决定的，分布式是存储一个个巨大的文件，大片大片去读写，很连续的访问模式，整个页的调度成本降低，数据访问成本降低

为什么要分页？

如果没有一个个的页，是全局的，分页就可以局部，页的调度也比较方便

 

![img](file:///C:\Users\asus\AppData\Local\Temp\ksohtml\wps3109.tmp.jpg) 

![img](file:///C:\Users\asus\AppData\Local\Temp\ksohtml\wps310A.tmp.jpg) 

![img](file:///C:\Users\asus\AppData\Local\Temp\ksohtml\wps311B.tmp.jpg) 

先找到满足price的例子，再去跟前面条件去对比

![img](file:///C:\Users\asus\AppData\Local\Temp\ksohtml\wps311C.tmp.jpg) 

Score price category 很多时候会用，适用范围更广

C是可能散落在空间的不同地方，因为没有score

D category没办法用，price不确定，因为price可能散落到任何一个点，但是使用到score就可以用到

A-B-C-D

有A;AB;ABC包含前缀就可以用，如果不包含，只是有后面的属性，如BCD就没办法用

比单独A好的原因：AB更好？

代价：键值变长，k变大，B树里面能够容纳的个数变小，这个树高度会增加，查询的性能会恶化

![img](file:///C:\Users\asus\AppData\Local\Temp\ksohtml\wps311D.tmp.jpg) 

C是可以考虑的，但数据被改了都要对a操作

A不带来很多要维护的代价

区分效果不好的如性别，几种颜色，洲

Selectivity=k/x>=1% 通常不需要创建索引，无效  属性是随机分布，除了id

 

B树相对于平衡二叉树，其好处为：一个结点的散出效果越大，高度越低 fan-out

如果是比较次数，B树比AVL更大，把一棵树变矮，并不是为了减少计算量，而是减少了I/O的次数  每一次比较是CPU访问内存的代价，但是真正要减少的应该是内存到硬盘中取东西的代价，即I/O代价，每次加载的是一block，最小也有512byte，里面可以装很多数据

树的高度决定I/O代价，而这个是最大的代价，目的是为了减少I/O代价，每个结点尽量要装更多，每一个结点应该要把一页用得充分。

所以AVL的计算代价并不差，但访存的代价比较高

重要的是树的散出多少，影响散出的ABC  一个结点用完一页，页的大小决定可以放多少指针

B树的平衡性，阶k->k/2-k 即指针（键值）的个数，这个性质决定

 

B树

Hash  key->Address(key) 构建在硬盘上面

block代价 N data k buckets  N/k即访问桶的代价  

点查询，确定k值，去查，无法应对范围查询

 

“##apple##”应该构建什么样的索引

R-Tree

LSM-Tree

 

用id查和用属性查 用很多数据

 

 

# 数据库设计

需求分析 软件设计  存什么  1.软件功能理解 2.概念设计      怎么存 怎么访问 3.结构设计4.物理设计5.实施

 

![image-20210921132834344](C:\Users\asus\AppData\Roaming\Typora\typora-user-images\image-20210921132834344.png)

![image-20210921142319352](C:\Users\asus\AppData\Roaming\Typora\typora-user-images\image-20210921142319352.png)

![image-20210921143447990](C:\Users\asus\AppData\Roaming\Typora\typora-user-images\image-20210921143447990.png)

![image-20210921145404788](C:\Users\asus\AppData\Roaming\Typora\typora-user-images\image-20210921145404788.png)

请针对以下需求设计一个文档数据库的模式：
一个关于电影、制作人员和演员的网站（类似一个简易的IMDB网站）。用户可以浏览每一部电影的简介和相关信息（出品年份year、电影类型type、时长duration、评级rating），以及其导演director、编剧scriptwriter和演员actor的列表。用户还可以浏览每一位导演、编剧或演员的信息（姓名name、性别sex、年龄age、简介info），以及他们参与过哪些电影作品film。导演、编剧或演员只是职位，一个人可以身兼数职。用户登录后还可以针对每一部电影、每一位导演、编剧或演员进行评价和打分，供别人参考。

##### 冗余属性：

有利于查询数据的性能

更新会下降，会增加开发的复杂度

尽量减少冗余？ 1.不现实，性能可能非常低下

扩展数据管理的server难度很大，99%读数据，读扩展：在应用层加一个cache（key-value Redis  memorycache） cache里面是json的一个个包  下一次就和自己访问cache中的jason file，不需要从数据库中去取，这样就解决了99%的问题

 在数组上面怎么建索引

倾向于在父类的方式上去存文档，如果两种类别差异很大，总是分开去访问，需要在两个上面去创建不同的索引

如果访问的方式基本雷同，就合在一起。

##### 文档数据库相对于关系数据库的优势

分门别类

# 为什么关系模型

SQL中一行行的是逻辑表达式，则可以进行声明式插叙语言，只需要告诉需要什么，计算机可以自己去找。

1.在软件开发的过程中，要使得软件开发的工程容易，App和DATA越简单越好

Ted Codd认为不利，因为要一步步通过指针让程序去找数据，一旦数据的结构去调整，则牵涉到要大量改app的程序，耦合度很紧。 所以最简单就是提出要什么，数据库自己去找

IBM有IMS，层次模型

UC Berkely  Mike Stonebraker   Ingres -> PostgreSQL

IBM ->SystemR

70年代后期 Larry  Oracle

所以是把数据变成一个个逻辑表达式

一阶逻辑基本可以计算，但二阶有的不可计算

关系代数是在逻辑上的裁剪，在计算机上运行会比较快，这种模型既是声明式的，可以满足逻辑，又可以计算快

##### 声明式的语言优势

程序简单；运行效率往往没有人编的好；运行过程可控性比较差

prolog第四代编程语言，现在我们使用的是第三代

索引可以优化选择，投影，连接，95%以上为了加速选择

 文档数据库选择就是文档的选择 find

关系数据库提供了很多不同的计算方式，不单单是选择，连接这种文档数据库时不提供的



选择如何实现？最简单把表遍历，把符合要求的元组取出来  只要再选择条件的属性上建立一个索引

投影？遍历表，把不需要的属性扔掉，再查重压缩一下（可能排个序啥的）

有index，就直接把index拿过来，把叶子结点遍历一遍，已经排好序的，不需要去访问表了

如果是πxyz，就用不到x，但可以创建一个xyz复合索引

连接？做一个二重循环，内循环的表把里面的每个属性和外面的表比对一下 在x上建个索引，可以提高效率

比如在R、S，S中的每一行去R中去找索引，这样就省掉了一重循环，还有更高效的方式



连接的个数：【0，R*S】

# SQL

#### 多表查询

select Student.Sno, Sname(因为学号又出现在Student，又出现在SC)

From Student,SC

where Student.Sno=SC.Sno and SC.Cno='c002';

#### 聚集查询

处理数据查找，还提供了计算的能力，aggregation，用来做统计，比如max,min,avg,sum,count这种

select * 所有的属性

Select Count(*) From Student   Count聚集函数作用在若干、多个属性时，数元组的个数 即3  count*

​                      3

结果是一张表

Select   AVG(grade) From SC

Select MAX(grade) From SC where Cno='C001'

首先筛选where中的元祖，然后再这些里面找到MAX的grade

#### 分组聚集

Select Sno, AVG(grade) 不可以再加入Cno

From SC

Group  By Sno;

即每个同学所有选了的课程的平均成绩，在每个组的内部用聚集函数



Having AVG(grade) > 90

要么就是分组属性+聚集属性要么只有聚集属性

对分组聚集group by的结果再筛选，用Having



假设我们有三个关系（同课程中使用的例子一样），其模式分别为

```javascript
Student(s_no, s_name, birthday, gender)
Course(c_no, c_name, credit)
SC(s_no, c_no, grade)
```

请写出以下信息需求的SQL查询：

1. 在数学课上成绩超过90分的男生姓名；

   Select s_name

   From Student,SC,Course

   Where Student.s_no=SC.s_no AND SC.c_no=Course.c_no AND c_name="Math" AND gender="male"

2. 数学课成绩超过历史课成绩的女生姓名:

   Student-SC-Course-M

   ​             -SC-Course-H

   

   Select s_name

   From student,SC SC_1,SC SC_2,

   ​			Course C_1, Course C_2

   Where geneder="female" AND C_1.c_name="数学" AND C_2.c_name="历史"

   ​		AND Student.Sno=SC_1.Sno AND Student.Sno=SC_2.Sno AND SC_1.Cno=C_1.Cno AND SC_2.Cno=C_2.Cno  AND SC_1.grade>SC_2.grade;

   好处是：有最优的方式去完成

   表 S1

   Select s_name, grade

   From Student,SC,Course

   Where Student.s_no=SC.s_no AND SC.c_no=Course.c_no AND c_name="Math" AND gender="female"

   表 S2

   Select s_name, grade

   From Student,SC,Course

   Where Student.s_no=SC.s_no AND SC.c_no=Course.c_no AND c_name="History" AND gender="female"

   

   Select s_name

   From S1,S2

   Where S1.s_name=S2.s_name AND S1.grade>S2.grade

   数据库优化不好的话，有优势

3. 平均成绩超过90分的女生姓名。

   Select s_name 

   From Student,SC

   Where Student.s_no=SC.s_no AND gender="female"

   Group by Student.S_no,s_name#不然的话可能会重名

   Having AVG(grade) > 90

   ##### 测验题：

   第*1*题：考虑以下4个查询 Q1: Select a,b From T1, T2 Where T1.c=T2.c And T1.c=100; Q2: Select a,b From T1, T2 Where T1.c=100 And T2.c=100; Q3: Select a,b From T1, T2 Where T1.c=T2.c And T1.c>100; Q4: Select a,b From T1, T2 Where T1.c>100 And T2.c>100; 说法正确的是：

   A：Q1和Q2结果相同；Q3和Q4结果不同；

   ------

   2.在学生表Student(s_no, s_name, birthday, gender)和学生选课表SC(s_no, c_no, grade)中求每个学生的姓名和平均成绩。哪个查询表达正确？

   D：Select s_name, AVG(grade) From Student, SC Where Student.s_no=SC.s_no Group By SC.s_no, s_name

   因为Select s_name，所以s_name必须要再Group By后面

   SQL规则：Select A  聚集运算 Groupby A，因为不然不知道分组的属性是否唯一

   

   B->C Select C Groupby B，那么C的取值一定是唯一的，

   不能这么写，系统不知道 Select C Groupby B,C

   不能直接写Select C Groupby C

   第*3*题：以下哪些查询是等价的？

   

   A：Select Count(*) From T Where b>100 Group By a 和 Select Count(*) From T Group By a

   ------

   

   B：Select Count(**) From T Where b>100 Group By a 和 Select Count(*) From T Group By a Having AVG(b)>100

   ------

   先Group By->Having->Select?

   C：Select AVG(a) From T Where a<10 Group By a 和 Select AVG(a) From T Group By a Having AVG(a)<10

   *done*

   

   T         

   a

   1

   14

   3    ->  AVG(a)

   4         1

   ​          3

   ​          4

   

   AVG(a) 按组求，每个组都是a

   AVG(a)

   1

   3

   4

   ------

   

   D：Select a,AVG(b) From T Where b>100 Group By a 和 Select a,AVG(b) From T Group By a Having AVG(b)>10

## 作业

1. 关系数据库让用户自行定义每一张表的Primary Key（主键），用于唯一识别表中的每一行数据。例如学生表student(sno, sname, birthday, gender)的主键可定义为为sno，宿舍表rooms(dorm_no, room_no, size, floor)的主键可定义为(dorm_no, room_no)（由宿舍号和房间号组成的复合主键）。在文档数据库中，用户无需定义主键，每一个文档都可以由系统自动产生的省缺ID进行识别。换句话说，文档数据库的ID属性起到了Primary Key的作用。请思考：关系数据库的Primary Key机制和文档数据库的ID机制有什么不同，各自的优缺点是什么？

   主键不定义也行，那为什么要定义主键？

   通常用来识别某个个体的属性作为主键 natural key 但有的时候会人为定义一个id，用id来做，即代理键surrogate key（文档数据库里面都是id，而不是natural key，那为什么会这样？)

   其实也可以加id在关系数据库里，还可以弄一个自增，让属性的每个取值都唯一，从而识别所有的行，可以干同样的事，而且在大量的应用都是这样的，弄一个自动自增的id，这种代理键的数据模式在关系数据库里面也是非常常用的。
   
   这种方式比较简单，经得起变化，比如：当两个学校合并时，需要更改pk，应用常常会发生变化，导致自然的这种natural key会变化，这样的调整有很大的代价，代理键是没有意义的，就是用来识别的，当改变，这个仍然可以不变，从而在关系数据库里也会大量使用
   
   缺点：不够直观
   
2. 关系数据库要求用户在使用一张表之前用DDL对表进行事先定义，并且给出表需满足的各种约束（比如主键、外键等）。文档数据库则不同，它通常不要求用户对文档集的结构做事先定义，甚至允许用户往文档集中插入任意结构的文档。请思考：关系数据库和文档数据库为什么使用了两种不同的功能设计？背后的原因是什么？

   关系数据库目的，后面的所有的数据管理都交给数据库，即数据库完整性给数据库

   尽量简单，数据管理的很多工作都交给DB，APP和DB之间的交互简单，职责明确，有关系代数这种信息的表达方式,DB本身也更强大

   但是太多的事情交给数据库后，未必处理得好，有很多细节，没那么强AI的能力，所以需要应用对数据有更多的控制能力，所以就是把DB的一些功能去掉，让APP去做

   文档数据库：应用需要保证数据的完整性，一致性，不能完全靠数据库，在应用的程序中需要编写额外的代码去保证

   交互会复杂，这些地方变了，那些地方变了，都要通过代码去写

   后续会有例子去解释

3. .如果我们在属性A上定义了Primary Key或Unique这样的约束，那么数据库将要求表中的任何一个元组在A上的取值都是唯一的。也就是说，当我们往表中重复插入A值时，数据库将立即感知到，并禁止我们这样做。请问：数据库是如何感知我们往表中重复插入A值的？

   在PK上创建INDEX（数据库自己创），查到有就不能再插了，通常不会受增长的太大的影响，一但创建了PK，则自动有index，unique也是自动就会创建index，而且在用这个属性去查的时候，自动用这个属性的index去查询

B+ 树索引的所有数据均存储在叶子节点，而且数据是按照顺序排列的，那么 B+ 树使得范围查找，排序查找，分组查找以及去重查找变得异常简单

## 测试题：

**第***1***题：外键约束起哪些作用？（1）告诉数据库系统数据中的引用关系；（2）明确外键所在元组存在依赖于它指向的主键的存在；（3）告诉数据库系统外键指向的主键不能被随意删除。**

**第***2***题：对于一张学生表Student (s_no, s_name, birthday, gender)，我们可以将主键定义在单个属性s_no上，也可以将定义在复合属性 (s_no,s_name) 上。请问那种方式更优？**

**第***3***题：你觉得在什么样的属性上适合使用Not Null这样的约束**

**第***4***题：关于SQL查询和关系代数之间的关系，以下哪个说法是不正确的？**

SQL（1992）的程序不需要变，换了一个数据管理系统也没事，带来了程序的可移植性，但是也固化了，也就是只要是关系模型的数据管理系统，必定要支持SQL功能，

虽然也是声明式的，但仍不友好，考研也会出SQL语言，一般不会超过10行，但是在银行。。有几百行，看都看不懂，就有点像过程式的语言，所以不是那么自然，但是已经变成标准了，一旦标准就固化了

Ted Codd 提出关系代数的人并不支持该语言

SQL分成：DDL(data defined language)定义关系数据库模式的语言  create table有什么属性，有什么约束+DML(data manipulation language) 对数据进行更新 包括insert update delete

+DQL(query)最复杂+DCL(control 控制权，有的人不能访问)



mongodb没有create collection，当往collection里面插入第一个文档时，那个collection就自然建立，也没有约束，可以往里面插入任何文档，但是关系数据库必须把表定义得非常完整，设计不一样，为什么？

约束很多：primary key(主键)，unique,not null ,Foreign key，对已经存在的数据的引用，一定是引用另一张的PK，这是一种很强的约束，导致  要维护好这个引用的约束（依赖） 在删除修改的时候要注意

如果是引用关系，如果另一张表有的话，才可以插入，不然插入不了

被引用的数据在删除的时候，也会牵一发动全身，因为不能引用空值，要么就是不可以删除，要么就会把那些引用了的也删了 delete cascade级联删除

也就是满足完整性、一致性的条件



### 主键：

在一张表里面该属性可以唯一识别其他属性，可以是单一，也可以是组合

如

person1  person2  relation

111        2222           siblings

主键(person1, person2)

### 主键有多个，但是如果把所有属性合起来作为主键的话，是否合理？

并不合理，主键的定义并没有提供任何的信息含量，没好处，反而可能会干扰



key的定义：

A->R

并且不存在A**属于A，使得A* * ->R



### 只能定义一个主键，人为选择一个键，那什么选择是合理的？

### 

不同的应用，not null约束不一样

出版物和出版社是依赖的关系，所以not null



关系数据库中的一个个表不是严格满足关系的定义，因为允许两条完全雷同的元组存在，如果没有定义主键，只有做了去重处理才是关系

投影是在关系上做，结构一定是关系，select distinct a,b from T

没有去重（select a,b from T)

### 多表查询

# 嵌套查询：

IN   >ALL()同时

​          ANY()任何一个就行了

相关子查询：

父查询使用的表/变量出现在了子查询里面

Select Sname

From Student S

Where EXIST(Select SC.Sno = S.Sno

​						AND SC.Cno ='C002')



所以就跟前面讲的简单嵌套查询不同，不能先通过查子查询再再在父查询中去查

类似于一个循环，for(S属于Student 每一个元组) 去执行子查询

1.S001->空

2.S002->代入 有没有选C002这门课，满足

。。。

可以利于书写？

视图(函数) 是一个虚拟的表 ，把常用的会被使用的方式包装成一张表

CREATE View M.Student AS

SELECT Sno,Sname,birthday

From Student

Where gender='M'

直接可以在视图上去做

访问控制，定义不同用户的权限，规定哪些视图是可以看的，哪些视图是不可以看的

先做视图的查询的表再做其他的

更新

Update Student

Set Sname="jl"

Where Sno="s001";

删除

Delete From Student

Where Sno="S001";

会考虑约束 外键

假设我们有三个关系（同课程中使用的例子一样），其模式分别为

```javascript
Student(s_no, s_name, birthday, gender)
Course(c_no, c_name, credit)
SC(s_no, c_no, grade)
```

请写出满足以下访问需求的SQL语句：

1. 删除所有平均成绩小于70分的课程；

2. 找到在所有课程上的成绩都超过课程平均成绩的学生。

   select s_name from student where s_no not in(select s_no from sc x where x.grade <= (select avg(grade) from sc y and y.c_no=x.c_no))

Delete From Course

Where C_no in  (SELECT c_no From SC Group By C_no Having AVG(grade) < 70);



where后面是没有办法跟avg 只能跟在having

做平均的时候是先要分组group by 然后才能筛选

或者

DELETE FROM Course

where (Select All(grade) from SC where course.c_no = sc.cno) <70

2.

Select *

From Student

Where S_no NOT in(Select s_no From SC X WHERE x.Grade <= (SELECT avg(grade) from SC y AND y.cno=x.cno) )



任意x F(X)或者G(X)

存在 exist 

存在x F(X) = 不存在x F(X)不存在



NOT IN {成绩小于平均成绩}



在from后面跟了两张表，后面没有where的连接条件，就会做笛卡尔积变为一张大表

mongodb用程序做

# 测试题：

第*1*题：以下查询将得到什么结果？SELECT COUNT(*) FROM Student WHERE Sno IN (SELECT Sno FROM SC WHERE Cno IN (SELECT Cno FROM Course WHERE Cname= '数学' ) AND grade > 60 ) AND gender = 'F';

------



A：选修了数学课的学生人数

------



B：选修了数学课的女生人数

------



C：在数学课上成绩超过60分的女生人数

*done*

------



D：选修了数学课并且在所有课程中成绩都超过60分的女生人数

第*2*题：以下查询将得到什么结果？SELECT Sno FROM SC Group By Sno Having AVG(grade) > (SELECT AVG(grade) FROM SC Where Cno = 'C001' );

------



A：在C001课程上超过平均成绩的学生学号

------



B：平均成绩超过在C001课程上成绩的学生学号

------



C：平均成绩超过C001课程平均成绩的学生学号

*done*

------



D：选修了平均成绩超过C001课程平均成绩的课程的学生学号

一旦有相关子查询，就会复杂了

第*3*题：以下查询将得到什么结果？SELECT Sno, Count(Cno) FROM SC x WHERE Grade >= (SELECT AVG(Grade) FROM SC y WHERE y.Cno = x.Cno ) Group By Sno;

------



A：在每门课上的成绩都超过该门课平均成绩的学生

------



B：每个学生在多少门课程上的成绩超过了课程平均成绩

*done*

------



C：每个学生在多少门课程上的成绩超过了他所有选修课程的平均成绩

------



D：每个学生在多少门课程上的成绩超过了所有人的平均成绩



SELECT *

FROM SC x                 		SC x  For Each x属于SC{where? 满足或不满足

​														X.cno平均成绩}  也就是用x再来查一遍表，查到跟哪些cNO相同的，再统计avg

WHERE Grade >=

​       (SELECT AVG(Grade)

​		FROM SC y

​		WHERE y.Cno=x.Cno)



所以就是对SC做一个过滤，把课程成绩大于这个课程的平均成绩的学生拿出来

SQL(DDL DQL定位要的数据，然后才进行DML的操作 DML对数据进行增删改 DCL不学)

函数作用：分模块，不用重复书写，最重要

视图的作用：1.书写2.控制用户权限，敏感数据屏蔽：（1）A可以访问，B不可以 （2）这张表的这几列可以访问，其他的不能访问，精细一点，如个体不能访问，但是平均的可以访问，这是用view 便可以达到颗粒度的访问

Create view ABC as

​	SELECT count,avg,sum

from 

group by

第*4*题：以下对视图的说法正确的是：

------



A：视图的使用可以提升查询的性能  使用函数不一定能提高程序的性能

material view 物化视图 暂存，以后不用去跑，其他不行

------



B：视图是虚拟的，因此不能在视图上实施数据的增删改  不一定

例子：

AS Select Sno AVG...   update avg=avg-1 有歧义，要说明是唯一的改法

删除一条数据是可以的

允许的情况是被你更新的数据可以唯一对应到原始表中，没有歧义

------



C：视图之上不能构建新的视图

------



D：视图的使用可以增加软件开发的效率

*done*



# 关系数据库的基本实现原理：

粗略的架构：

APP--SQL--->  DBMS(计算层(查询处理)+存储层)

​     <--------

mongodb的计算功能很简单，主要是如何存储数据

也是存储在一张张的页里面，然后再串起来，先要将表分解成一行行，每一个页里面存放若干个元组，通过若干页面把整张表的所有元组存放，通过表头结构(可以像inode)串联起来，也可以是某种索引串联



1.翻译：SQL翻译成关系代数表达式(确定的)，多个，执行效率差异很大interpretation

2.查询优化 最优查询计划query optimization   预测(AI)

3.查询执行query evaluation



数据处理的性能问题：

算法(时间复杂度 #CPU cycles(没有考虑访问数据的时间，如果是数据密集型的话就应该是CPU访问内存的数据  数                               据库里的数据是在disk上，内存和硬盘是I/O通道10ms/100微s)

性能 I/O次数  好的算法，是次数低的算法

空间复杂度)



# 选择算子的实现：

selection

1.100次 一共100页

2.索引访问 4次i/o 访问了4个页面

先会去看有没有索引，但并不是任何时候都使用索引

也可能无法提高效率，因为可能where里面的覆盖面特别大，有很多指针指出来。

# 投影算子的实现：

先排序

不能完全容纳到内存里

要在disk上面去排序？可以常规的算法O(nlogn)=i/o

要考虑的不是CPU 而是在I/O上面效率高

数据访问局部性

B是容纳数据的页面的个数 3*B

![image-20211021223005932](C:\Users\asus\AppData\Roaming\Typora\typora-user-images\image-20211021223005932.png)

# 作业：

1-请根据你自己的理解找出以下查询的最佳关系代数查询计划。

```
Select sno, sname
From Student, SC
Where Student.sno = SC.sno
And grade<60
And cno in
	(Select cno
	From Course
	Where cname = 'Math I');
```



2-对于关系表 R(a,b,c,d)，我们在属性b上创建了一个B树索引，那么投影操作 πa,b(R)的执行是否可以利用该索引？如何利用该索引？

如果是建立在a.b上，直接去访问叶子结点，依次读进来，在1B merge就行了

如果是a/b，可能有帮助，用索引去访问数据是随机的过程



3-课程中我使用了外部排序（External Sorting）的方式实现了投影操作的去重。请你设计另一种去重的方法，不使用排序，仍然可以达到很高的效率。

3*B（D)块的数量 次I/O  扫描3次I/O就ok了

哈希去重 3*B



# 测验：

第*1*题：对于查询 Select Distinct sno, sname From Student, SC Where Student.sno=SC.sno And cno='C001'，请用常识判断以下哪个查询计划的执行效率应该最高？（假设SC在cno上有索引，Student在sno上有索引。）

------



A：（1）Student和SC在sno上做连接；（2）在（1）的结果上做cno='C001'的选择；（3）将（2）的结果在sno, sname上做投影。

------



B：（1）在SC上做cno='C001'的选择；（2）将（1）的结果和Student在sno上做连接；（3）将（2）的结果在sno, sname上做投影。

------



C：（1）在SC上做cno='C001'的选择；（2）将student在sno, sname上做投影，将（1）的结果在sno上做投影;（3）将（2）的两项结果在sno上做连接。

*clear*  这样的处理没有必要，直接join用索引，否则会得到中间表，上面没有索引，故错误，直接比对的话

先做选择再做连接会更高效，视情况而定

------



D：（1）在SC上做cno='C001'的选择；（2）将（1）的结果在sno上做投影;（3）将（1）的结果和Student在sno上做连接；（4）将（3）的结果在sno, sname上做投影。

*done*

第*2*题：对于一个关系代数表达的查询计划 (σ(A) ⋈ σ(B)) ⋈ C，它有几种等价的执行方式？（σ表示选择操作，⋈表示连接操作，这里A表和B表之间的连接属性与A表和B表之间的连接属性是不同的。）

------



A：2种

------



B：4种

------



C：10种

------



D：15种 没有考虑笛卡尔积的情况，所以多增加一个步骤，就会增加很多倍，会用很多剪枝的方式

*done*

第*3*题：给定一张表R(a,b,c,d)，假设一个查询为Select a,b,c From R Where a=10 OR b=100。以下说法正确的是？

------



A：索引对该查询无法提供帮助

*clear*

------



B：在a或b上创建索引都可加速该查询的执行

没用？用a索引，不全，所以就没有价值

------



C：在a和b上各创建一个索引可加速该查询的执行

再取个并集

*done*

------



D：在a,b上创建一个复合索引可加速该查询的执行

第*4*题：对于两个等价的查询计划 σ(A) ⋈ B 和 σ(A ⋈ B)，要判断它们哪个执行效率更高，以下哪些因素的作用最小。

什么情况下，先做连接的情况更小？

A:10^6  B^2 差距很大

选择 10^4

------



A：B上是否有索引

------



B：A ⋈ B的结果集大小 中间的每一步结果尽量小

------



C：系统内存空间的大小  内存很大，可以吧中间结果放进去

------



D：系统硬盘空间的大小

*done*





文档数据库

索引 就查索引 没有就遍历

SQL数据库

大部分按照行存的，创建索引，B树/哈希

DQL(select   from     where    join    group by)



查询执行引擎：进行大量计算，会随时从存储引擎里面拉自己要的数据，2种方式(扫描、索引访问index scan/access)

查询优化：给一个SQL变成效率最高的查询计划，10几万行代码

DBA(找查询起来有问题的地方，有几个地方查询时间太长)



# Join的实现原理：

外部设备（内存、CPU之外）：硬盘、mouse、显示器  可以没有但通常需要 包括网络

进程可以执行 只需要CPU 内存

交互即I/O过程

如果是云的场景，多个计算机，不同计算机之间的通信，也叫I/O

磁盘的带宽非常差，->SSD 提高了20倍 2GB CPU和内存通信的带宽:10GB   多核的话可能达到100GB



for r 属于 R

​	for s 属于 S

​		if(r 连接 S)	 R的元组数量 |R|×B(s) (s表的页数)      I/O操作的次数

​			output r.s	当元组数量很大，不好

改善方式：

##### 1.嵌套循环：把R里面的M个元祖拿出来

for M 属于 R           设内存里面能够容纳的页面的个数为M，B(R)是R表的页面的个数

​	for s 属于 S

​		if(M 连接 S)	B(R)+B(R)/M×B(s) (s表的页) I/O操作的次数    小的表作为R，极端的情况是R特别小，B(R)/M=1

​			output r.s

把R表进行打包，分成一大块一大块，再进行匹配

100*10/3

##### 2.散列连接：hash join

先对R表、S表做数据预处理：

一次扫描把所有的结果计算出来，首先散列的操作：

B(R)+B(S)  首先要将所有数据读到内存里去做散列，再写出到硬盘上的桶里，同样是B(R)+B(S)

，桶两两直接做连接，读出来在内存里做连接，B(R)+B(S)，总共3*(B(R)+B(S))

330

有的时候散列更好

##### 3.索引连接：index join

|S|*h

当s很小的时候，很好

查询优化的一部分

100*log10

数据密集型要注重i/o的次数

# 测验题：

第*1*题：如课程中提到的，嵌套循环算法的I/O代价可以表示为 B(R) + B(S)*B(R)/M，其中B(R)代表外循环表的页数，B(S)代表内循环表的页数，M代表内存能容纳的页数。那么以下哪种方案无法提升该算法的效率？

------



A：增加内存容量

------



B：将小表放到内循环（作为S），大表放到外循环（作为R）

*done*

------



C：将大表放到内循环（作为S），小表放到外循环（作为R）

------



D：更换速度更快的硬盘

*clear*

第*2*题：课程中介绍了两种连接操作执行算法，嵌套循环和散列连接。以下哪种场景更适合使用嵌套循环算法？

------



A：一张表很大，一张表很小。小的表几乎可以容纳到内存中。  

此次，嵌套是B(R)+B(S) 但哈希仍然是3*(B(R)+B(S))

如果是纯内存：(嵌套：|R||S|     哈希：|R|+|S|)

*done*

------



B：两张表都比较大，都无法容纳到内存中。     		HASh更好

------



C：两张表都比较小，都可以容纳到内存中。			都无所谓了

------



D：几乎在所有情况下，散列连接的效率都更高。

第*3*题：假设R表有1000行，S表有100行；每页可以容纳10行数据（无论R表或S表）；内存可以容纳3页；R表和S表均有x属性，并且在x属性上均创建了索引；假设x具备很高的辨识度并且分布均匀。那么，理论上实现R和S在x上的等值连接的最佳算法是：

------

B(R)=100 B(S)=10 M=3

A：嵌套循环  10+4*100

------



B：散列连接 3(110)=330

------



C：索引连接   访问大的表的索引代价更低，100*R的索引访问代价

如果索引是B树，每访问一个节点就是一个I/O，所以索引访问代价就是B树的高度+1

如果每个节点>=10个指针，那么3层就可以了，所以height<=3



一般去访问一个B树，第一个结点可以缓存在缓冲区，所以height<=2

*done*

------



D：都一样

*clear*

# 作业

若内存很大，在

1-在做散列连接的时候，可能会遇到数据分布不均的情况，比如在连接属性上取值为k的元组特别多，多到连内存都容纳不下。请问这种情况应该如何应对？

1.哈希函数要做选择，但是如unniversal hash 可以把分布得更均匀

2.但是连接属性上取值为k的元组特别多，不管哈希怎么选，都会有桶特别大，放不到内存里面去，这个代价免不了，结果的size就会非常大，就在这个桶上做个嵌套循环就行了

3.两张表都特别大，内存特别小，在做hash的时候，内存是由一个个缓冲区，那么缓冲区就会限制桶的数量，导致每一个桶都特别大，那么桶同样放不到内存，

|R|>M^2，就把桶拿进去再哈希，可以无限做下去，就可能变成5*(B(R)+B(S))





2-除了课程介绍的连接算法，你是否能想到其他高效的算法，它甚至在某些情况下比前面介绍的算法更快？

去重：排序、哈希

用排序的方法去连接，归并sort merge(join的方式)，R排序3*(B(R)) S排序3*(B(s))  merge B(R)+B(S)

共4*(B(R)+B(S))

可以优化成3*(B(R)+B(S))



把表分成一块一块，排好序再合并再合并

​												一步merge 少掉一次变成3*(B(R)+B(S))



大部分情况下，选择hash join，但有的时候会选择sort merge(通常和表的大小没关系，就是这些表已经是排好序了，有索引了，不论是一张表排好了还是都排好了)



3-请为以下问题设计一个I/O代价低的算法：
给定一张表R(a,b,c,d)，找到R中在属性a上发生次数少于k次的所有取值。（如果R中一共有n个元组在属性a上的取值为x，我们称x在R中发生了n次；假设R很大，无法容纳于内存中；假设a的不同取值个数很多，这些取值也无法都容纳于内存中。）

Select a,count(*)

from R

group by a;

如果a的取值很少，例如是gender，只有两个取值，维护两个数组

数组再大一点，再加一个hash

a的取值很多，这个个数使得无法在内存中创建这样的数组，就排个序，代价为3*B(R)，最后可以再扫一遍B(R)

当超过K值的时候就扔掉，以后遇到这种情况就不考虑，在排序的过程中可以利用这一点

# 关系数据库的设计：

文档数据库设计步骤：需求分析：看业务是什么，流程是什么  概念设计：确定数据库里面应该存什么样的数据，用来描述什么样的信息，要把信息的概念一个个罗列出来 结构设计：数据怎么存，用一张表？多张表？关系？

概念设计，用对象模型来存储：

面向对象的模型

当时在文档数据库中为什么评论要嵌入在文章里面，是因为所有的评论是必定和文章相关的，用户去访问评论的时候必定是先访问文章，他们两个总是一起被呈现出来，所以从访问效率的角度看，。。。

但关系数据库不同，概念设计：ER图，挺像面向对象的，只不过描述对象之间联系的时候有更细致的

entity relationship

对象     关系

椭圆代表属性，什么样的属性应该存在数据库里面

菱形代表关系

长方形代表实体

唯一属性（ID）：工号、工程号  双箭头

单值属性：一个员工只能有一个名字 单箭头

多值属性  两个单箭头

![image-20211028210545754](C:\Users\asus\AppData\Roaming\Typora\typora-user-images\image-20211028210545754.png)

一个联系可以存在在两个实体之间，也可以存在与一个实体直接，也可以存在多个

![image-20211028210824947](C:\Users\asus\AppData\Roaming\Typora\typora-user-images\image-20211028210824947.png)

父类和子类的关系，弱实体的关系



1.对于所有的实体类，首先把单一属性，单值属性放到一张表

2.对于多值属性，单独为技能构建一张表，主码必须是多值属性和员工号的组合

3.联系，如果是一对一，那么项目放到员工或者员工放到项目都可以；如果是多对一，那么应该是多的那一张表加一的信息；

都不需要额外一张表

多对多：新建一张表，3个属性，员工ID，项目ID，联系的属性time，员工ID和项目ID共同构成主键

![image-20211028211650480](C:\Users\asus\AppData\Roaming\Typora\typora-user-images\image-20211028211650480.png)

在博客中：

对象替换成了实体，

![image-20211028212002130](C:\Users\asus\AppData\Roaming\Typora\typora-user-images\image-20211028212002130.png)

![image-20211028212326008](C:\Users\asus\AppData\Roaming\Typora\typora-user-images\image-20211028212326008.png)



主要就是概念设计，ER图把设计变得机械化格式化

# 作业 ER图：

1. 下图所示的ER图刻画了四类实体，对“员工”而言，另三类实体（合同工、咨询专家和普通员工）都是它的子类。也就是说，员工拥有的属性，另三类实体都拥有；而子类拥有的属性父类未必拥有。请尝试设计这四类实体对应的关系表。

![image-20211029105145161](C:\Users\asus\AppData\Roaming\Typora\typora-user-images\image-20211029105145161.png)

3种方法：

1.1个关系：一张表 所有父类子类属性放在里面  	太宽了，里面有很多空值，占空间的，很稀疏----子类并不多

2.3张表 3张表都有员工的属性，同时新增加不同的新的属性  问题比好处明显：如果不知道是哪个类型的，要每张表都要找一次；如果信息不完整，只知道是一个员工，还没有归并在某一个类别，可能没地方去存，可能要新开一张表，新入职未确定

3.4张表 单独把员工属性领出来，增加一个属性，类型，后面3张表子类  更清晰，问题是要join，sql是要连接，变复杂，性能会下降 ---子类很多

![image-20211029105729583](C:\Users\asus\AppData\Roaming\Typora\typora-user-images\image-20211029105729583.png)



1. 请针对以下需求设计ER图，并构建相应的关系模式：
   
   一个关于电影、制作人员和演员的网站（类似一个简易的IMDB网站）。用户可以浏览每一部电影的简介和相关信息（出品年份、电影类型、时长、评级），以及其导演、编剧和演员的列表。用户还可以浏览每一位导演、编剧或演员的信息（姓名、性别、年龄、简介），以及他们参与过哪些电影作品。导演、编剧或演员只是职位，一个人可以身兼数职。
   
   每一位演员在其参演的电影中都扮演一定的角色。用户在浏览电影时，除了能看到演员信息，还能看到每位演员扮演了什么角色。用户在浏览演员时，除了能看到他（或她）参演的电影，还能看到他（或她）在每一部电影中扮演的角色。（注意：一位演员可以在一部电影中扮演多个角色。同一个角色也可能由多名演员扮演，比如，年少时由一位演员扮演，年老时由另一位演员扮演。）
   
   用户登录后还可以针对每一部电影、每一位导演、编剧或演员进行评价和打分，供别人参考。



数据库的功能接口是什么？ 怎么实现？(CRUD操作是怎么在数据的存储上去做，数据怎么存储)

关系->范式（一些规则指导）去除冗余

![image-20211029101149930](C:\Users\asus\AppData\Roaming\Typora\typora-user-images\image-20211029101149930.png)

这种不自然仍然是由于冗余产生的，所以不要将姓名和学号放在一张表里面

前面的在应用中难

应该怎么去做设计然后最后的结果符合某一范式，最好给一套流程，也就是需求分析(软)、概念设计(ER图)、结构设计(RDB设计)

实体可以由单个、复合属性唯一识别，关系表里也要唯一识别，其ID为所有参与实体的ID共同组成

![image-20211029103110460](C:\Users\asus\AppData\Roaming\Typora\typora-user-images\image-20211029103110460.png)

如果购买是一个联系，那么记录的就是张三是否购买了牙膏，如果要更复杂的信息，那么购买就不能是两个实体的联系，因为每一个购买的行为是不能够有这两个实体的ID唯一确定   不是探讨行为有没有，而是发生的时间，次数，变成订单

![image-20211029103538655](C:\Users\asus\AppData\Roaming\Typora\typora-user-images\image-20211029103538655.png)



# 数据冗余

有时候把数据扔掉，仍然可以找回来，就是越规范，规范可以由冗余度衡量

有的时候用冗余

总的原则：避免冗余信息

原因：1.会占过多的额外空间，消耗存储资源

2.增加更新表的代价

![image-20211102152804882](C:\Users\asus\AppData\Roaming\Typora\typora-user-images\image-20211102152804882.png)

用户名并不是由key(主码)决定的，而是单独由uid确定的，正是因为不是由主码确定，所以导致冗余



函数依赖  Functional Dependency  FD

uid->u_name

pid->p_name,price

而uid不等于primary key   pid不等于primary key

一旦不等于，就会出现冗余

如何去除冗余？

# 数据冗余的规范化

![image-20211102184658123](C:\Users\asus\AppData\Roaming\Typora\typora-user-images\image-20211102184658123.png)

模式分解  实际上如果概念设计做的好，就会很自然得到左边的规范化设计

分拆开的数据量会少很多 normalization

第一范式 1NF

第二范式 2NF...

严格性递增

# 冗余带来的好处

![image-20211102185703581](C:\Users\asus\AppData\Roaming\Typora\typora-user-images\image-20211102185703581.png)

可以加速查询

当我们需要经常去访问数据库，而我们又不常常去修改一些属性的时候

1、提速 2、副作用小

每次都要去连接，所以效率不高，所以增加冗余

当我们要对数据做统计，需要大量的扫描，而这样是很耗时的，所以使用冗余信息 total_sales，

但是每次都要新插入一个订单的时候都要更新total_sales

![image-20211102215541546](C:\Users\asus\AppData\Roaming\Typora\typora-user-images\image-20211102215541546.png)



![image-20211102220023645](C:\Users\asus\AppData\Roaming\Typora\typora-user-images\image-20211102220023645.png)

一旦有冗余，就要保持一致性，要更新。

![image-20211102220246920](C:\Users\asus\AppData\Roaming\Typora\typora-user-images\image-20211102220246920.png)

![image-20211102220702979](C:\Users\asus\AppData\Roaming\Typora\typora-user-images\image-20211102220702979.png)

从ER图到文档模式：

在文档模式中没有那么多的限制



当应用是什么特点？才增加冗余

从应用的角度来讲，每次去访问sid，都要去访问sname，而且sname的更新是很少的，基本不变，所以为了访问效率高，就要增加冗余

带来的收益，减少连接，而且也没有什么代价

# 测验题：

第*1*题：假设有一个员工表 Employee(ID, Name, Address, Phone#)（其中ID为主键）。最初电话号码Phone#是一个单值属性，即每个人只有一个电话。后来发现，有少量员工有两个电话号码，且都需要记录。你会如何对数据库的结构设计进行调整？

------



A：将Phone#的数据类型变成字符串，将两个电话号码用分号隔开，一起存在同一个字段中。

------



B：将主键变为 (ID, Phone#)，将有两个电话号码的人在表中存两份。

------



C：将模式修改为 Employee(ID, Name, Address)，Phone(ID, Phone#)。规范化的方式 phone有多值属性

------



D：将模式修改为 Employee(ID, Name, Address, Phone#, Phone#Alt)，其中Phone#Alt用于记录另一个电话号码。因为一个人的电话不会特别多，简单又方便

#### 这个设计的前提：对大部分人而言是单值属性，对于少部分人，取得值也很少，所以这样子可以

#### 但是如果多值属性的属性非常多，就不适合这样，但大部分都情况下，都很少就可以

第*2*题：关于数据冗余的说法，哪一项是不正确的？

------

都是会，也可能不会

A：冗余会增加数据更新的代价

------



B：冗余会增加数据删除的代价

------



C：冗余不会增加数据查询的代价

*done* 

用的不好，同样会增加查询代价，比如表太大了

------



D：冗余会增加软件开发的复杂度

*clear*

数据库并不知道这两个名字是指的是同一个名字，并不会自动的全部update完，只能程序员自己做，所以有冗余的时候，只能写更多的程序去维护一致性

数据库物理设计，很常用

第*3*题：对一张属性很多的表（通常称为“宽表”），为了提升表访问的性能，我们可以选择将表拆成两份或多份。比如，将 Employee (ID, name, salary, tax, mgr#, dept#) 拆成 Employee (ID, name, salary) 和 Employee (ID, tax, mgr#, dept#)。请问做表拆分的原则应该是什么？

------



##### A：让同时被使用到的属性（即出现在同一个SQL中的属性）尽可能位于分拆后的同一张表中。

*done*

------



B：让经常被更新的属性尽可能位于分拆后的同一张表中。

*clear*

------



C：让被索引的属性尽可能位于分拆后的同一张表中。

------



D：让可能为空的属性尽可能位于分拆后的同一张表中。

第*4*题：假设有一张表：行程表（旅客号码，导游号码，打卡景点），记录了哪些旅客被哪些导游带领去了哪些地方。我们发现了很多如下形式的规律：不同的旅客在同一位导游的带领下，如果去了景点A，那么必定也会去景点B。请问数据库中是否存在冗余信息，可以如何处理？

------



A：没有冗余

------



B：有冗余，但无法通过结构设计去除

------



C：有冗余，适当改变结构设计后可去除

*done*

就把规律拿出来放到另外一个地方（硬去）

但会不会丢失了信息？路线？

发现这些，其实说明丢失了信息，即路线的信息，所以有大量冗余

多值依赖，路线与景点的关系，路线只能决定一组景点，这是要新开一张表

![image-20211103090929147](C:\Users\asus\AppData\Roaming\Typora\typora-user-images\image-20211103090929147.png)

------



D：以上说法均不对

# 作业

一个校园学术活动网站。所有学生和老师都可以成为网站的用户，将自己组织的学术活动在网站上发布，比如学术讲座、读书会等等。发布活动时需要指定活动的标题、时间、地点、类别和内容。一旦活动发布，其他用户就可以浏览活动的内容并报名。通常活动有人数限制，活动发起人可以选择部分报名者成为活动参与人，也可以开放给所有报名者参与。活动结束后，参与人可以给活动打分，并写评论记录活动内容。每位用户发起的所有活动将永久被网站记录，其他用户可以随时查看他发起活动的历史，以及平均得分。

请先用ER图为以上场景设计数据库模式，然后再根据应用访问数据库的方式对模式进行优化。（提示：需考虑索引的使用。）



在开发Web应用的时候，90%都是面向对象语言。 数据最好是一个个对象，而不是DB中的一张张表，ORM工具，用户可以把一个对象直接存放在RDB，也可以从RDB直接取出对象，不再使用SQL。

一个个对象如何实现映射？

一个对象就是一行行的数据，每一个类对应一张表

但是对象与对象直接有引用的关系，一对多的存在多的那边

多对多，额外创建一张表，但这些过程都是藏在ORM后面，只需要定义这些对象即可



文档数据库很好兼容了对象的特点，文档数据库里存的就是一个个对象，所以很容易放对象，但是关系数据库不是

mismatch 数据库层和应用层错位

# 事务处理

# OLTP vs OLAP

事务型                      分析型

数据状态                    历史

账户  购物车              购物历史

课程类                       车轨迹

其实就是信息

而且状态只能通过数据来证明，而不是物理的状态

更多是从历史的数据去找有价值的东西



非常不同

两种应用模式

稳定性不会进行大量查询，只是进行简单抽取

 正确性 更新	   强大数据处理能力，复杂SQL



事务处理功能

# 数据的正确性

![image-20211104133557742](C:\Users\asus\AppData\Roaming\Typora\typora-user-images\image-20211104133557742.png)

还可能出故障 web server/DB

包括数据库内部实现的机制和提供的事务处理的接口



多个用户提交操作，索引的数据和表中的数据不一样，发生了异常

或者只是完成了一部分



原子性 atomocity

要么全部执行要么就没发生

要让操作都是瞬间操作

# undo日志 恢复到之前

![image-20211104135057638](C:\Users\asus\AppData\Roaming\Typora\typora-user-images\image-20211104135057638.png)

日志：在硬盘上单独留出一块，去恢复数据库，看哪些操作没有完成的，让修改的数据变成原来的值，即回滚

在第一步执行之前，写log(O1 start)

在做第三步之前，写log(O1.A原始值 3)

当要在硬盘上对B进行修改前，写log(O1.B 3)

最后完成 log(O1.end)

才算完成

# redo日志

每次在写入磁盘之前，记录修改之后的值，然后对A进行修改的操作推到最后一步

只有在O1结束了，才真正对硬盘上的值进行修改

![image-20211104135545734](C:\Users\asus\AppData\Roaming\Typora\typora-user-images\image-20211104135545734.png)

故障 出现在4,5之间，由于没有o1.end，什么都不用做，因为数据还没有写入到硬盘

若出现在7,8之间，都有了，就会把硬盘上的值恢复成操作之后的状态



redo对于内存的消耗比较大，因为都要修改后才能写入到硬盘，如果内存不够用的话这个操作就无法进行下去，新的修改加不进去，但是效率比较高，对数据的修改可以推迟到操作结束之后，不需要跟操作同步进行，只是适当时候对日志进行记录，日志是一条一条追加进去，顺序写入，速度快。

undo 相反，写一个日志，写一个数据，是跳来跳去



# undo/redo日志

不但包含修改之前的值，还包括修改之后的值，完整，redo，不完整,undo

# 测验：

第*1*题：是系统使用了undo日志，在故障发生后，发现日志记录如下：<o1,start>, <o2,start>, <o2,A=5>, <o2,B=4>, <o2,end>, <o1,A=3>，<o1,C=3>。请问：系统恢复后A的取值是多少？

------



A：5

------



B：4

------



C：3  o2已经结束了，所以就不是5，正确答案应该是3

------



D：不知道

log(o2,start)

log(o2,A=5)

write(A=3)

log(O2,B=4)

write(B=5)

log(o2.end)<- 一旦把o2.end的日志记录到日志里面，代表这个操作结束了



log(o2.start)

log(o2,A=3)

log(o2,B=5)

log(o2.END)<-一旦把这个写到日志里面，就代表操作完成

write(A=3)

write(B=5)



第*2*题：我们用log表示将日志写到硬盘，用write表示把数据写道硬盘。如果系统使用undo日志，那么以下哪个操作执行序列是不能保证原子性的？

------



A：log(o1,start), log(o1,A=5), write(A=6), log(o1,B=3), write(B=4), log(o1,end)

*clear*

------



B：log(o1,start), log(o1,A=5), write(A=6), write(B=4),     如果故障恢复在这里 log(o1,B=3), log(o1,end)  只要log在write之前

*done*

------



C：log(o1,start), log(o1,A=5), log(o1,B=3), write(A=6), write(B=4), log(o1,end)

------



D：log(o1,start), log(o1,A=5), log(o1,B=3), write(B=4), write(A=6), log(o1,end)

第*3*题：我们用log表示将日志写到硬盘，用write表示把数据写道硬盘。如果系统使用redo日志，那么以下哪个操作执行序列是不正确或不可能发生的？

------



A：log(o1,start), log(o1,A=5), log(o1,end), write(A=5), log(o2,start), log(o2,A=6), log(o2,end), write(A=6)

------



B：log(o1,start), log(o1,A=5), log(o1,end), log(o2,start), log(o2,A=6), write(A=5), log(o2,end), write(A=6)

*clear*

------



C：log(o1,start), log(o1,A=5), log(o1,end), log(o2,start), log(o2,A=6), log(o2,end), write(A=6)

这种情况是会出现的，01的操作都没有做，因为数据在改的过程中，是有缓存的，然后直接在缓存中弄，所以写到硬盘上就只有一个操作  也是redo日志的好处，可以减少i/o的次数

------



D：log(o1,start), log(o2,start), log(o2,A=6), log(o2,end), log(o1,A=5), log(o1,end), write(A=5), write(A=6)

*done*

o2,o1都结束了，o2先结束，o1后结束，所以write的时候o2在前面，最后应该是o1的值把o2的值覆盖掉了

涉及到并发控制的问题

在end之后改，可以任意时间，但是顺序要注意

第*4*题：以下哪种情况是数据库系统的操作原子性（atomicity）无法保证的？

------



A：两个并发的CRUD操作从效果上一定一个在前一个在后。

------



B：任意一个CRUD操作要么发生在故障之前，要么发生在故障之后。

------



C：在故障发生前已经开始的CRUD操作一定会顺利完成。

*done*

------



D：在故障发生前没有结束的CRUD操作一定会被撤销。



# 作业

课程中提到了Undo/Redo日志，但没有介绍其具体工作机制。请思考它的具体工作机制。假设有如下一个操作，请使用你想到的Undo/Redo日志机制阐述整个操作的执行过程。

```
Begin
log(start O1)
	read A from Disk into x;
	x = x+5;
log(A x x+5)
	write x to A on Disk;
	read B from Disk into y;
	(1)
	y = y+x;
log(B y y+x)
	write y to B on Disk;
log(O1.end)
    写出x到A
    (2)
    写出y到B
End
```



如果是在(1) down，那么记录得不完整，就会undo会之前的值

如果是在(2)down，那么记录都完整，那么就会redo后面的值



对write就没有限制，在这个操作之前也可以，在之后也可以，都可以保证原子性

![image-20211105112752362](C:\Users\asus\AppData\Roaming\Typora\typora-user-images\image-20211105112752362.png)







日志能够保证操作的原子性，但这个是在系统故障之前/之后，实际上没有讨论多个操作之间的影响，保证互不干扰，即并发控制机制

锁、时间戳的方法

对数据进行适当的加锁，可以防止干扰，一旦要访问数据A，就lockA，同样对B也是如此

![image-20211109150411517](C:\Users\asus\AppData\Roaming\Typora\typora-user-images\image-20211109150411517.png)

在操作完全结束之后，同时释放A，B的锁，可以保证O1先于O2执行，或者相反，两阶段锁 2PL，加锁是一个完整的阶段，解锁是另一个阶段

用1把锁也可以实现互斥，为什么要用两把锁？



![image-20211110082823266](C:\Users\asus\AppData\Roaming\Typora\typora-user-images\image-20211110082823266.png)

如果是1000个数据，1把锁，那这1000个数据都要去拿这把锁，会出现排队现象，无法并行，正确性可以保证，但是系统性能低下



操作原子性的保证：

1. 面临系统故障，日志

2. 操作同时发生，锁

如果是应用：事务处理接口

# 应用层面的数据正确性：

![image-20211109151705491](C:\Users\asus\AppData\Roaming\Typora\typora-user-images\image-20211109151705491.png)

# 用标志位

![image-20211109152228253](C:\Users\asus\AppData\Roaming\Typora\typora-user-images\image-20211109152228253.png)

# 用消息队列

![image-20211109153200216](C:\Users\asus\AppData\Roaming\Typora\typora-user-images\image-20211109153200216.png)

微服务也是这样的

保证操作是幂等性，就可以从头做，可以用消息队列的模式

![image-20211110092827377](C:\Users\asus\AppData\Roaming\Typora\typora-user-images\image-20211110092827377.png)

# 测试题：

第*1*题：以下哪种加锁方式可以保证操作的原子性？

------



A：lock(A); update(A); lock(B); update(B); unlock(A); unlock(B);

------



B：lock(A); lock(B); update(A); update(B); unlock(A); unlock(B);

------



C：lock(A); update(A); lock(B); unlock(A); update(B); unlock(B);

------



D：都可以

*done*

![image-20211110083601049](C:\Users\asus\AppData\Roaming\Typora\typora-user-images\image-20211110083601049.png)

![image-20211110084603277](C:\Users\asus\AppData\Roaming\Typora\typora-user-images\image-20211110084603277.png)可能会出现O2先拿到B的lock，如果这样的话，会以1234去执行

C的话保证了次序，O1一旦拿到第一个lock，就能保证先拿到B的lock，因为加锁的次序是这样

A,B,C加锁和释放锁的规律是一样的，都是在拿到所有锁之前不会释放任何一把锁，只要确保在拿到所有锁之前不去释放任何一把锁，就能保证原子性，即两阶段锁2 phase locking

如果1000个数据，可能效率很低的。但数据库比较短小，如果出现这种状况，会去规避，一旦有锁，就会阻塞

C的性能最好，因为加锁的时间最短，尽量早去释放锁，尽量晚去加锁

![image-20211110090518553](C:\Users\asus\AppData\Roaming\Typora\typora-user-images\image-20211110090518553.png)

会出现死锁，解决死锁的方式，定个时，通常给10us可以解决，如果10ms没解决，就把它kill，就把它undo一下，就给每个操作一个timeout

第*2*题：日志和锁需要配合起来使用才能完整确保操作的原子性。用log表示将日志写到硬盘，用write表示把数据写到硬盘，用lock和unlock表示加锁与解锁。如果系统使用undo日志，那么以下哪个执行序列是日志和锁的最合理搭配方式？

------



A：log(o1,start); log(o1,A=5); lock(A); write(A=6); unlock(A); (1)log(o1,end);

A和B/C/D的时机不同，释放锁的不一样，一个是把操作结束写到硬盘上后，再释放锁，晚释放锁一般没有问题，

面对故障的时候会有问题，发生在（1）

回滚之后会O2会变成5，但明明已经标志O2结束，7一定是要确保日志结束之后释放锁。

如果要早释放锁，那么需要其他机制，比如log(O2,end)放在o1.end后面

![image-20211110091628690](C:\Users\asus\AppData\Roaming\Typora\typora-user-images\image-20211110091628690.png)

------



B：log(o1,start); lock(A); log(o1,A=5); write(A=6); log(o1,end); unlock(A);

*done*

------



C：log(o1,start); log(o1,A=5); lock(A); write(A=6); log(o1,end); unlock(A);

​								已经在访问A的值是5了，所以要在访问A之前。。

------



D：lock(A); log(o1,start); log(o1,A=5); write(A=6); log(o1,end); unlock(A);

第*3*题：以下哪个操作不是幂等（idempotent）的？

------



A：向一个集合里插入一个元素

------



B：从一个集合里删除一个元素

------



C：对一个数据进行赋值：X=10

------



D：对一个数据进行自增：X=X+1

*done*

# 作业题

某博客网站提供一键取关并删除评论的功能，即当一位用户取消自己关注的某位博主后，他在该位博主文章中的评论将被全部删除。假设故障随时可能发生。请想办法保证该功能程序的正确性。

两种都可

user{

ID :b

follow['a']

namesync='done'

}

comment{

blogger_id[ 'a']

follower_id['b' ]

comments['good' ]

}

delete follow['a'] from user

set user.namesynsc='undone'

for (comment.follower_id='b' and comment.blogger_id='a')

deletecomments['good' ]

set user.namesynsc='done'

toy example

做完了的操作是不可以回滚的，有的数据库比如mongobd不提供事物处理的功能，每次去对它进行点赞的时候，都要去记录下来，而且操作不要重复去做

1.versioning 

Task{like movie_ID todo movie{like: version123}就知道点过了，就不会														自增		actor{like:500,version 123}										

​		version 123}

Task{like

​			256	}

256一定要在task123之后做

1. 思考题：在一个电影评论网站上，用户可以给电影点赞。网站记录了每个电影获得的点赞数，以及每一个导演和演员获得的点赞数。一位用户给一个电影点赞会让该电影的点赞数增加1，同时还会让电影的导演和演员的点赞数都增加1。假设故障随时可能发生。请想办法保证点赞功能程序的正确性。

   film{

   film_id['101']，likes_num:1000

   }

   director{

   d_id['122']，like_num:1000，film_id['101']

   }

   a_id:['12222']，like_num:1000，film_id['101']

   }

   Task{

   ID:'1312，status:'Todo',work:'122‘,’101‘，’12222‘+1'}

   insert task

   update user.id=[101] add like_num+1

   update d.id=[122] add like_num+1

   update a.id=[12222] add like_num+1

   update task.id=[1312]

   set status as done
   
   


无论是标志位还是消息队列，对于程序员要求都很高，那么这个一致性可否由数据库做，而不是在程序里面做。可以交给数据库去做。那么这种功能就是事务处理 Transaction Processing  OLTP

一个事务就是一段程序

![image-20211111211807237](C:\Users\asus\AppData\Roaming\Typora\typora-user-images\image-20211111211807237.png)

有时候事情做到一半，不希望程序提交，可以abort或者rollback

一个事务的原子性是不可能做到操作级别的原子性，ACID

atomicity 原子性：单指这个事务要么做过了要么没做，不是事物瞬间发生

C一致性：一般

I隔离性：isolation  readcommited  

repeatable rand

D 持久性 durability 一旦事务提交无法撤销

只要有事务处理，就要有保证ACID，C一般不会去谈

1.日志AD

2.并发控制I

不完全和操作的一样，可能会放松严格的程度

# 事务的使用

![image-20211111231311931](C:\Users\asus\AppData\Roaming\Typora\typora-user-images\image-20211111231311931.png)

一个用户的迟疑会影响其他用户的订票，这是不合理的

![image-20211111232323711](C:\Users\asus\AppData\Roaming\Typora\typora-user-images\image-20211111232323711.png)

原则：事务应该是短小的  并且把人机交互，网络通信排除在外

第2步和1,3无关，把它放在中间，无故增加了事务的长度，所以在事务完成之后去调用服务

![image-20211111233139189](C:\Users\asus\AppData\Roaming\Typora\typora-user-images\image-20211111233139189.png)

# 作业

一、请思考：当我们使用Abort撤销一个事务时，是否需要记录相关的日志以确保事务的原子性？如果Abort过程中遇到故障，应该怎么办？

不会造成问题，当abort过程出现中断，是不会有问题

如果在abort后面，需要在日志里面记录

1.abort之后再记录abort log(T,abort) 写完这个日志之后，才能释放加在T1,T2的锁

2.一种什么都不记





二、在一个同城快递应用的数据库中，有两张表。其中一张为订单表，记录了每一条订单的订单号、送货人信息、收货人信息、货物的信息、发货的起点地址和终点地址、以及送货的状态（包括“新提交订单”、“已接单”、“已取货”、“已送达”四种状态）。另一张为配送表，记录了每个配送员的信息、配送员当前所在的区域、以及配送员正在执行的订单号（当订单号为空时，表示配送员还未接单）。

该应用只允许每个配送员同一时间执行一个订单。该应用对外提供多个功能，包括：

1. 用户下单：用户将订单提交给系统。
2. 配送员接单：配送员浏览自己所在区域的订单，并且选择一个订单接单。
3. 取货：配送员到发货起点取货，并更新订单信息。
4. 完成配送：配送员将货物送达终点，并更新自己和订单的信息。

每次功能调用可能会访问一张或多张表。应用在实际运行时，五种操作会并发进行。此外，运行应用的服务器随时可能遇到故障，我们需要保证：在服务器宕机重启后，用户的订单能够被顺利完成。为此，我们需要使用事务来保证应用的正常运行。例如，用户下单的过程可以按照如下的伪代码执行：

功能1：用户下单

```
Begin Function
   同用户进行交互，获得订单的所有信息;
   Begin Transaction;
	   访问订单表：新插入一条元组，标志订单状态为“新提交订单”;
   Commit;
End
```

请给出功能2、3、4、5的伪代码。

2 Begin Function

​		配送员浏览自己区域的订单，并选择一个；

​		Begin Transaction

​		判断订单是否已经被定掉了：在修改之前就要做判断if failed: abort;

​		更新订单表：

​		commit;

end



3 Begin Function

​		配送员浏览自己区域的订单，并选择一个；

​		Begin Transaction

​		判断订单是否已经被定掉了：在修改之前就要做判断if failed: abort;

​		更新订单表：

​		commit;

end



4 Begin Function

​		配送员浏览自己区域的订单，并选择一个；

​		Begin Transaction

​		判断订单是否已经被定掉了：在修改之前就要做判断if failed: abort;1     什么时候不能去接单

​		更新订单表：

​		commit;

end



# 期中考试后：

# 面向新型存储介质的数据管理

闪存：

块里面有64个页，不支持原位更新，想要更新B页，必须将整个数据块擦掉，再写，造成写放大（想写的数据和实际写的数据的比例64）

闪存转换层，异位更新，避免原来的数据块擦除再。。。，造成空间浪费，原来的地方标记为invalied，相当于垃圾，垃圾回收要定期地把数据重新读一遍再整理，贪心算法，每次选收益最大的，垃圾回收的技术在进步

随机读不需要垃圾回收，随机写会造成大量垃圾，读写差异现在比较小，一般现在2-3倍。

如果连续写，不会产生垃圾，就没有垃圾回收

连续写比随机写快很多。

利用闪存的并行，粗粒度IO读写，多个IO请求

## 3个特性：

随机读>随机写

连续写>随机写

利用闪存内部并行提高整体带宽

针对特性进行优化

块设备，需要弄到内存，再被CPU



非易失：掉链了数据仍然存在里面

非易失内存很贵如今

字节寻址，可以直接被CPU直接寻址，写满读快（读写不对称）

性能接近DRAM



根据这些新特性来重构之前的数据库算法

1.DRAM全 扔掉 不支持

2.memory mode

DRAM 64G 用户不可见 热数据，数据没法保证写到

NVM 用户可见 256G 冷数据

RAM包含DRAM NVM

3.APP DIRECT MODE

想存在哪就在哪



CPU有片上缓存 L1,L2 cache，通过cache间接访问主存

一个cache line 64字节

DRAM TB级数据

写了int x=20 不一定写到DRAM，需要指导在怎么写，更新后不会写， 都cache line被evict才回写，write-through有写放大的问题

先进先出，clock算法，代价低，每方位一次bitset置为1，lie算法，不停操纵链表，代价高



cflush 剔除写下去，耗时

clwb 知道热的，先留在cache

sfence：在写指令之后插入写屏障，

int x=10

+sfence

int y=11

CPU这2个没有关联，并行

NVM ：确保一致性



线性哈希：地址空间线性增长

基于闪存的索引技术：

一个桶设为cache line大小

轮询式的方法分裂，如果是虚拟的还没有分裂，要回溯去查找



内存里的hash算法应用到数据库

数据库按页管理，先读目录再读桶，2次IO，放到数据库里桶的大小，以页为密度？

设一个cache line，就会有很多桶共享一个，所以数据页

目录代价去掉？

或者目录很小

1024只要10个数组

连续存储只需要地址

页中断 想读一个数据页的时候没有

只需要保留很小的数组就可以把整个hash桶

跟新代价0(1) 分裂O(2) 把原来数据搬出来写到新的桶里

粗粒度：写一个页细粒度 同时写4个页

0123->4567粗粒度IO，并行的方式

带宽没打上去，算法不行，并行粗粒度，把已有算法进行改造



桶写到其他地方，异位更新。如果数据分布到多个桶，IO代价高

一个hash不能读10次IO

log region  读性能提高上去

先读Skecth，数据有没有在里面，2个IO

2个IO还是不能忍受，需要定期地把读密集的数据合并，就没有数据页了

如何判读读密集还是写密集？

sketch概率总结 7-10个bit把8个字节总结出来

哈希指纹 类似于  

业务逻辑简单

基于NVM的索引技术：

B+树索引

只能叶结点做无序，

写带宽和读带宽是不一样的

# 

```
演员拍过的电影
SELECT personID,Acting.movieID
    FROM Movie,Person,Acting
    WHERE personID=Acting.actor AND Movie.movieID=Acting.movieID
    AND name='Tom Hanks') as t1,


所有导演拍过的影片
(SELECT personID,name,Directing.movieID
    FROM Movie,Person,Directing
    WHERE Person.personID=Directing.director AND Movie.movieID=Directing.movieID
    ) as t2
```

# 9.1 OLAP与数据科学

分析处理，主要处理历史数据

OLTP通常存放状态的数据  如购物车里的数据

博客写下来，又可以状态：因为整个博客系统的功能依赖于数据，要事务处理

​						同时历史：可以看成历史去挖掘

状态数据TP				历史数据：由历史的数据发现规律去建模AP



![image-20211116214847909](C:\Users\asus\AppData\Roaming\Typora\typora-user-images\image-20211116214847909.png)

从TP的系统里归拢合并 最终放到数据仓库里

ETL extraction transformation loading 加载到集中化的数据仓库，提供分析能力OLAP，从而去洞察业务



在data cube（多维）上面slicing dicing把cube切掉

中间都是fact

去掉月份其实就是合并

roll up and drill down

MOLAP		ROLAP(关系数据库去存储)



cube->更广义	有很多ai的模型，分析处理

data lake   厂商：Snowflake  databricks在云厂商构建湖  未来的Teradata，提高数据分析的基座	中国还没有出现这样的企业			中国大部分数据还是在自己私有的系统	分布式数据系统是数据湖里面的数据处理

很多的云厂商 AWS AliCloud  Azune

不需要看见服务器

不选用云平台提供的数据分析，是怕绑定太深



Superset一个BI的工具，建在关系数据库上面，就可以提供分析的能力



![image-20211116220607318](C:\Users\asus\AppData\Roaming\Typora\typora-user-images\image-20211116220607318.png)

# 文档数据库vs关系数据库

![image-20211116221901929](C:\Users\asus\AppData\Roaming\Typora\typora-user-images\image-20211116221901929.png)

应用开发者角度

1. 文档数据库在现在的开发环境具有更自然的使用界面，OLTP的应用

2. 关系数据库基于SQL，SQL表达能力强，建立在关系模型。查询的过程可以委托数据库去查询 OLAP的应用，有的OLTP    具备更强数据处理能力

   aggregate 平均 会有点涉及AP

   
   
   应用开发者：状态数据   AI/算法：历史数据
   
   
   
   数据的生命周期：收集->整理->分析->结果(展示，或者一个模型，如一个推荐系统的模型，新闻也好。。。应用到新的业务)  是历史数据
   
   80,90年代叫数据仓库，商务智能（像银行、电信）BI 做决策
   
   收集的数据放到文件系统(excel里)，最主要的是一变成格式化的文件，需要构建程序对文件进行处理管理；数据库系统，通常不是mongodb/postgresql  在比较大的场景里，用其他的更针对OLAP的如数据仓库
   
   TP构建APP，软件工程师	数据分析师偏统计	算法工程师训练模型AI	数据科学家end to end
   
   软件系统的体系架构来看：
   
   ![image-20211116223132920](C:\Users\asus\AppData\Roaming\Typora\typora-user-images\image-20211116223132920.png)

不同数据库的构建思路

![image-20211116223603725](C:\Users\asus\AppData\Roaming\Typora\typora-user-images\image-20211116223603725.png)

如何选择系统

![image-20211116224110188](C:\Users\asus\AppData\Roaming\Typora\typora-user-images\image-20211116224110188.png)

请思考：课程中使用的博客应用例子更适合使用哪种数据管理系统来构建？文档数据库还是关系数据库？

OLAP很少对单个数据修改，批量输入数据，比如物联网的应用，传感器收到的数据要不停灌进去，不是简单的查询，对大量数据进行统计分析跑一些算法；OLTP很多增删改查，简单的查询





# 可用性：

复制多个节点构成副本集是为了保证mongodb数据库的高可用性

语句alter table student add constraint uq_id unique(id) 执行后为Student加了id唯一约束

满足BCNF的一定满足3NF，反之则不然

关于Raft协议，并不是每一次选主都能成功

在R的哪一个属性组合上创建索引对于以下查询没有帮助：select c,a from R where a>x and b<y

ac  ca  bc  b   ca不行

被索引的属性经常出现在where字句中对创建索引是有利的

关于逆范式化，可以减少应用程序与数据库之间的耦合度是错的

redo日志相对于undo日志的优势是i/o性能更好

关于线性一致性，如果操作A在操作B开始后结束，那么A对数据的修改对B一定不可见是错的





一个系统处于正常工作状态的时间比例

2个9代表几个月有几个小时用不了，2个9可能会让位给3个9

微信，2个9无法容忍 99%

银行，3个9,1年有几个小时不响应，金融行业里面3个9难以容忍，那么这几个小时可能引发市场动荡，资金链断裂  一般至少4个9

如何达到5个9？99.999%

银行一定要买大型机，很稳定，能保证系统达到5个9,2,30年没有任何问题，性能无抖动，ups支撑电量供应，双电源

->云：很多计算机组成的计算中心  每一个结点大概10万美元 99-99.9

每个计算机3个9，多台可能2个9

如何在google计算中心这种每天都有故障发生的云平台上部署金融系统？



高可用=容错鞥里，实现方法：冗余结点+数据复制，结点发生故障时，切换到冗余结点。

硬件没办法，只能从软件角度：

加一个backup，两台机器一模一样，除非两个机器同时不可用，Service才不可用，1-0.1%^2->6个9 99.9999%

3台机器->

通过冗余

每一个计算中心后面有backup，中心和中心之间也有backup。比如交通银行浦西、浦东、广东建设一个center 

用什么样的技术手段实现？

## mongodb容错方案：

设定之初，就是要在云，故要有backup。

一主两备：

primary时刻保持3者一致，心跳指令，过一段时间发送指令，即仍在，ms级，一旦primary出故障，心跳不正常，那么2个secondary感知，，communicate，那么其中一个变成primary，开始接受用户请求，可能以广播的形式通知Client。若之前的primary复活，那么只能变成secondary，接受新的primary的更新，保持数据同步。

为什么3台机器，而不是2台机器？

看似简单，实则复杂，必须要3台

##### 2台

如果secondary先发生故障，没事；如果primary先，secondary看不到primary心跳，timeout，claim 自己primary，当s1修复之后，更上节奏

那么只要其中一个在线，就没问题

##### 但是：

secondary发现对方没心跳，s1不知道什么原因卡了一下，但没死，自己并不知道自己卡了，觉得还是primary，那如何决定谁是primary，出现争议

如果相互之间通信不了，都claim自己是primary，那么就会产生争议

除非有第三方仲裁

只要有其中2个保持一致，通过投票的机制，从而把第3个投出的异议解决掉

数据一旦定下来就没有办法解决了

### 共识机制：

一个集群多数结点正常->系统可用

拜占庭将军问题 Byzantime Generals Problem

如何让部队达成一致

常见共识机制：

Paxos:两个人没法达成一致，可以有3个人或者5个人，如果有两个不出故障，可以让他们达成一致；只要其中任意3个相互之间可以通信，另外2个出问题仍然可以实现。

Raft分为3部分：

1. 选组 有一个leader，所有请求发给leader，如果leader出现故障，，选一个新的leader，以前的leader不能做leader了，但是回到之后会自动变成follower
2. log replication leader把信息发送给follower，让他们保持一致，一定要大多数follower都接受才更新结束  把redo日志发过去
3. safety规则，如何在日志出现冲突让日志保持一致，如何保存leader日志最新



这次的信号把信息广播给大家

如果一个secondary down了，那么leader会把现在状态给他

follower接受不到信号了，发起投票，说选我，其他人就是谁先让我投它就会选谁，这个过程一定会得到一个leader，没有任何一个人的票过半，重新投



有一个turn，原来是第2轮，turn已经变成了第4轮，自动变成





没有主了，要选主，s1，s4不配做主，因为数据不是最新的，所以在选主的过程中还要把最新的位置，中间还有一个比较的过程，保持一定是日志最新的人

也就是保证日志一定是最新的

raft.github



# 扩展性问题：

# 分布式数据库

mainframe 大型机 一以前计算机就是很贵的
会考虑可用性问题，特别复杂，每个人负责一个部分，有特别多冗余，一旦有机器坏了，不会影响机器的运行
PC是乔布斯年轻的时候，比较廉价
云平台的每一个机器都是廉价的，随时会坏掉，CPU过热就down掉了，上升到软件层面，一个sever复制多份，通过共识协议，不会影响
mongodb天然就是如此
移动互联网是第一代苹果出来的，instagram2010退出，推出首日就爆掉了，遇到了很明显的扩展性问题
pokemon go 游戏，4天5天就要赶上twitter

备战双11，部署机器，每个终端都要提高服务的
古老的方式scale up升级本身的服务器，增加CPU，硬盘，处理不了很强的负载增加
scale out 云计算中心

app server复制一份 相当简单 无状态，可以无数次被复制，因为不保存数据，只不过就是每一次起一个线程去跑
到网关的时候分布到不同的sever

问题就是db，如果也复制，问题是db有状态，复制多份给不同的server，运转一段时间就会不一致，就会变得很负责
不单单CRUD操作多，数据量也需要扩展，
如果相当于每个db都做，那就没扩展起来，二维数据本身就越来越多
把数据分成一块一块的，去访问相应的数据库系统，问题是怎么分
随机分有其可行之处，但问题很大
按照业务划分，
middleware 了解那些数据存在那个db，分发到哪个库上面去
不是很精致，处理的场景也不是很全面的

划分和查询分解有很大关系，
如果实在要做，只能在应用层去做了，不要去做having的过滤操作，由应用服务器去做最后查询处理的步骤

分不了就要在应用上去做

所以用分布式数据库或者并行数据库，对应用而言，是单节点，对外接口是一样的，内部会处理，还没有实现
架构
用哪一个架构？
shared everything  可以由一块CPU
disk 缓冲区不能变得很大，但是同样可以一个CPU去处理，可以访问到所有数据
 nothing
不能交给一个CPU处理，要分成不同的部分各自去处理
跟硬件本身资源的配置有关
数据一块块存在不同节点硬盘，CPU要不要去访问其他节点的数据，如何nothing，CPU去访问内存，物理距离也很重要
Disk/IO
Network
Memory

M>I>N  VS M> N> I
第一种架构，去访问对方的M，通过网络，是特别慢的，内存作为缓冲区的优势就没了，因为buffer是为了加速IO，第二种，一定要通过N去访问D，不行。第三种，尽量会用本地，只有要交换数据的时候才会用到网络带宽。

第二种，访问本地和异地没有大的差别，交给一个CPU去做，不用分拆开工作，比较好。第三种，任何任务都要分解分拆的，本地化的需求变得低的。

如果M，N很接近，那么第一种也可以，内存也可以共享
现在的云平台 
SSD做硬盘，带宽2GB/s 可能会往下做 冷数据放这里
万兆网的以太网，10Gb/s  1GB/s
如果不是万兆网,IB网络，就会快了 10GB
仍是case1

数据处理的分配，怎么查，操作原子性如何保证
1.挨个分 round robin 每个节点参与
2.hash partitioning 文档数据库id，做一个hash确定应该到那个节点，有利于查
缺点 不均匀 
3.按照数据的取值人为对数据进行划分，最有利于访问数据。range partitioning
更难把数据分得均匀

数据分好后就是如何访问数据的问题，
关系代数的并行化
数据划分的属性和要查询的属性一样，

6个连接再做合并
数据的传输代价很大 而其实很少的结果
R3 S2不同节点上 如何连接
半连接 先扔一些数据 降低通信代价，筛选出来后再讲S表筛选过后到发往S表
broadcasting join 把期中的一个表在另外一个节点上去做连接
partitioned join 数据分片
A分成3个 0-10 10-15 15-30 按照链接的属性在第三方的节点上去做，假设网络带宽是最稀缺资源
R S表数据传一遍 再多的节点也只是这样
broadcasting 3倍R的大小



2021.12.1Lecture 21 week13 期中sql大题 

# 数据切分  分布式数据库

见week13的手写笔记



2021.12.3  Lecture22

# 扩展性问题：

一个云的计算中心有很多机柜，电源基本上是双电源  机房里的电源叫UPS，这些电源来自于不同的电路系统，整个机房有冷却的设备，机架上面是放着很多服务器，交换机，最复杂的是电线。

这个系统要能够容错

高容错的协议：HA  Raft 

几台机器相互之间backup 当其中有机器down掉之后，又有其他的来backup，这样容错性就高

所有的结点都要用起来，系统要变成可扩展的模式

分布式系统可以看成是一个个结点共同去处理一些问题，然后还要进行扩展



Document DB和SQL SB在这样的基础设施上面哪个的扩展能力会更好？

通常假设结点之间是通过网络连接，内部之间有内存，网络要慢的，自己去做CRUD是快的，所以决定速度就是使用带宽是多还是少

如果大量使用带宽，拓展性不好

大部分人认为document DB可以支撑更好的拓展性，对于网络的带宽消耗更少



nosql运动，拒绝使用sql，其中一个原因就是sql的拓展性不够好，涌现出来了很多数据库系统，这些系统的扩展性比较强，常见分成4类

#### 1.key-value stores:  Riak,Voldemort, Redis

数据组织方式:<key,value>

数据访问方式Put(key,value)	Get(key)	Delete(key)

数据都不处理的，就是一团放在那里，拉到应用程序去弄就好了

也没有其他index，在key上有一个索引，也不会允许手动创建索引，查询也不可以进行复杂的像mongodb 

没有文档结构

#### 2. wide column store  google的big table  Hbase

每一个网页有几百个属性，很多个网页就是1万个属性，关系数据库没办法存，因为要建一张有1万列的表，而有的行就都是空的，表就是稀疏的，而且这张表也很难组织

进行压缩，所有东西都在一张表里面，没有join		每一行可以看成一个文档

#### 3. document DB

#### 4.图数据库 不讲了

为什么文档数据库的扩展性比较强？

1. 延迟问题：网络访问延迟要大于内存访问延迟,nosql可以节省网络的开销，(1)不跨结点连接(2)和进行事务处理，这些代价很大

   扩展能力依赖与数据局部性：同时被访问、被修改的数据尽可能位于同一结点

文档数据库是以对象为单位存储，有层次的结构，一个个对象都是在单个结点，不会跨结点，这样cost就会小

但是关系数据库要掰开，要拆成一块块存在很多表里，所以对象的一部分在一个结点，另一部分在另一个结点，容易出现这样的情况，当把对象从这个数据库读出来的时候就要做join，变成一个对象，这个就是代价，同样地，要去修改的话，数据是一个对象，但是它分散在不同的地方，就要用分布式事务处理的方式，除非能够进行很好的数据划分，使得都在一个结点。

很多时候要用应用驱动做设计，会加冗余，是逆范式化的，冗余加上去，就可以规避很多跨结点的访问，这样一个请求一个文档就可以满足要求，所以在文档数据库中加上冗余可以加强扩展性。

2phase commit很慢，一旦使用文档数据库，这样的需求就很低，即使要多个文档，也避免使用事务，用其他的方式，在应用上面如消息队列，为了更好地扩展性

咖啡店：用消息队列：排号  两条队不能保证原子性，但是可以处理，但效率高

​			2-phase commit  协调者 所有人都排在和协调者通信，可以保证原子性

所以不会用分布式事务的方式去处理原子性



#### CAP理论

 网上去解释为什么noSQL流行是错的

分布式系统的能力分为了3个类别：

C一致性：所有节点访问同一份最新的数据副本

A可用性 ：每次请求都能获取到非错的响应，但是不保证获取的数据为最新的数据

P分区容错性：通信故障时，系统的任意结点都正常工作

只能兼顾其中的2个

不存在CA，都是在P存在的情况下讨论的，所以CAP不能用来解释问什么noSQL的流行，不能说传统的DBMS是CA

传统的DBMS有CP和AP两种配置方式，例如oracle的两张日志复制方式：Eager-复制后再返回CP

Lazy 返回后再复制 AP

Mongodb也是 取决于访问数据的方式 read concern AP/write concern CP 写的操作要传递才行

AP的代表 Dynamo

12.15

# 备份及其他

​			日志和高可用没办法处理：存储设备坏掉了，日志不行，可以用高可用，一个结点坏了，可以用另一个；程序出错了，从而在往数据库里写数据的是错误的数据，日志可以，undo日志可以恢复到出错之前的状态，前提是还有日志，redo日志不行，高可用不行，要看什么时候出错，因为可能老的日志已经被扔掉了；人的误操作，日志和高可用都不行，因为删表的时候日志都不会记录，那要保护系统可以预防人为的错误，就是备份

Backup,通常一个企业会每天备份一个copy到另外一台机器 增量数据也可能会

数据的拷贝与迁移，数据能够移来移去的能力和数据备份有关系的。



# Backup vs Replication

备份需要停下来，高可用不需要

数据存档archiving：将不再使用的旧数据从数据库中移除，并转移到线下设备。比如电话记录、转账记录一年之前不让查，因为系统已经把它移出去了，释放线上资源，保证系统的运行效率

无论是备份还是存档，都是在磁带(大部分 一个盘可以装几个T，一般都是顺序读，随机的能力是很差的)、磁盘 这些比较便宜的东西

磁带存储系统：视频，大的数据中心是这样的	IBM也是主要的

云存储上去做，AWS S3，相对安全，存在云上面，便宜，这种就是用磁盘，因为规模大\																																																																																																								

给一个数据 1分钟访问一次  可以放在disk上吗 是磁盘是固态硬盘，如何量化？

看成本，一个数据放在一个器件的成本：存储开销+访问开销

越下面的设备，访问开销越高，上面是存储开销大

访问开销和访问频率有关，存储开销固定的	内存

backup的访问频率很低，放在任何一个设备里访问开销都很低的，所以看存储开销了

5 mins rule 应该放在内存里 jim Gray 80s-->2 mins

# 数据管理系统的多样性：

DB-Engines.com

PG开源的 使用频率接近商业，闭源下降、开源上升，2020已经达到了

商业的数据库的点：oracle的营收在降，microsoft在涨(Azune  很多来源于mysql，而不是sql server），也是2020相等

云：AWS(亚马逊) Azune



时序数据库，增加时间滑动窗口

图数据库，快速的join：欺诈识别，关联交易

时空数据库

# 搜索引擎系统

数据里面的属性不确定













